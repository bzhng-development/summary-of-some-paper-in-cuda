# Attention Heads of Large Language Models: A Survey

**ArXiv:** [2409.03752](https://arxiv.org/abs/2409.03752)
**Authors:** Zifan Zheng, Yezhaohui Wang, Yuxin Huang, Shichao Song, Mingchuan Yang, Bo Tang, Feiyu Xiong, Zhiyu Li
**Institutions:** 

## ðŸŽ¯ Pitch

This paper offers a groundbreaking framework for understanding how attention heads in decoder-only LLMs facilitate reasoning by systematizing their roles into a cognitively-inspired, four-stage process: Knowledge Recalling, In-Context Identification, Latent Reasoning, and Expression Preparation. By consolidating scattered mechanistic insights into a cohesive model, it not only clarifies how these heads collaborate but also provides actionable methodologies to enhance LLM performance, offering both practical solutions for reducing errors and boosting interpretability in AI research.

---

## 1. Executive Summary
This survey systematizes how attention heads inside decoderâ€‘only large language models (LLMs) contribute to reasoning. It proposes a fourâ€‘stage, cognitively inspired frameworkâ€”Knowledge Recalling (KR), Inâ€‘Context Identification (ICI), Latent Reasoning (LR), and Expression Preparation (EP)â€”and maps dozens of known â€œspecial headsâ€ and the methods used to discover them onto this framework (Figure 7; Sections 4â€“5). The work matters because it translates scattered mechanistic findings into an operational picture of how heads collaborate across layers (Figures 8â€“9), and it clarifies experimental toolkits and benchmarks to study them (Section 6).

## 2. Context and Motivation
- Problem addressed
  - LLMs achieve strong performance yet remain largely black boxes. Understanding their internal reasoning â€œbottlenecksâ€â€”especially the role of `attention heads`â€”is a central challenge (Introduction; Figure 1; Section 1).
  - Prior interpretability surveys emphasized early Transformer variants or techniques, often predating modern decoderâ€‘only LLMs and emergent capabilities (Section 3.3). This leaves a gap in headâ€‘level mechanism understanding for current LLMs.

- Why it matters
  - Practical impact: Mechanistic insight enables targeted interventions (e.g., reduce hallucinations, improve truthfulness, strengthen longâ€‘context retrieval). Section 1 and Section 4.4 describe heads like `Truthfulness`, `Accuracy`, and `Retrieval` that can be manipulated to improve behavior.
  - Theoretical significance: Heads are natural â€œunitsâ€ of inference in Transformers. Clarifying how they read from and write to shared `residual streams` (Figure 4; Section 3.2.1) provides a coherent account of information flow through layers.

- Where prior approaches fall short
  - Older surveys focus on attention variants or encoder models (e.g., BERT) rather than decoderâ€‘only LLMs with emergent behaviors (Section 3.3).
  - Many mechanistic studies analyze one task or one head family in isolation; crossâ€‘task generality and interâ€‘head collaboration are underexplored (Section 8.1).

- Positioning
  - Scope: decoderâ€‘only LLMs, attention heads as the focus (Section 2), with FFN mechanisms summarized later (Section 7.1).
  - Contribution: a unifying framework for head functions across tasks and layers, plus a clear taxonomy of experimental methods (Sections 4â€“5) and evaluation resources (Section 6).

## 3. Technical Approach
This is a survey that builds a structured model of how attention heads operate, grounded in the Transformerâ€™s math and a cognitive analogy.

Step 1 â€” Formalize how a head works in the model
- Layer computation (Section 3.1; Equations 1â€“2):
  - Each layer has two residual blocks. The first adds the multiâ€‘head attention output to the input; the second adds the FFN output:  
    `X_{â„“,1} = X_{â„“,0} + Î£_h Attn_â„“^h(X_{â„“,0})` (Eq. 1) and `X_{â„“+1,0} = X_{â„“,1} + FFN_â„“(X_{â„“,1})` (Eq. 2).
- Singleâ€‘head computation (Section 3.1; Eq. 3â€“4):
  - A head computes attention weights via queries and keys and writes values through an output matrix:  
    `Attn_â„“^h(X) = softmax(Q K^T) V O` (Eq. 3).
  - Expanded view (Eq. 4):  
    `W_Q W_K^T` is the `QK matrix` (controls â€œwho to read fromâ€), and `W_V O` is the `OV matrix` (controls â€œwhat to write backâ€).  
  - Key concept: heads â€œreadâ€ from the shared `residual stream` via QK and â€œwriteâ€ back via OV (Figure 4; Section 3.2.1).

Terminology used throughout (Section 3.2):
- `Residual stream`: the running sum of embeddings and previous layer outputs at each position; it is the channel all heads and FFNs read from/write to (Figure 4).
- `Activation patching`: replace an intermediate activation with one from a different run to test causal contributions (Figure 5; Section 3.2.2).
- `Ablation`: remove or zero out components or activations to measure effect (Section 3.2.2).
- `Logit lens`: map an intermediate vector through the unembedding to see which tokens it favors (Section 3.2.2).

Step 2 â€” A fourâ€‘stage cognitive framework for head functions (Section 4; Figures 6â€“7)
- Motivated by cognitive models (OAR and ACTâ€‘R; Section 4.1), the survey maps head roles to four stages:
  1) `Knowledge Recalling (KR)` â€” retrieve parametric or experienceâ€‘like knowledge to seed reasoning.
  2) `Inâ€‘Context Identification (ICI)` â€” locate and summarize structural, syntactic, and semantic information in the prompt.
  3) `Latent Reasoning (LR)` â€” integrate and transform information to infer answers or intermediate states.
  4) `Expression Preparation (EP)` â€” aggregate, amplify, and align internal results with surface tokens for output.
- Layerâ€‘wise pattern: shallow layers skew toward KR/ICI, midâ€‘layers to ICI/LR, deep layers to LR/EP (Figure 8), with exceptions on specific tasks.

Step 3 â€” Map concrete head types into the framework (Section 4; Figure 7; Tables 2â€“3)
- KR examples (Section 4.2; Table 2):
  - `Memory Head` retrieves relevant parametric knowledge triggered by enriched entity features written by shallow FFNs (Section 4.2).
  - Taskâ€‘specific biases: `Constant Head` and `Single Letter Head` in MCQA initialize attention over choice letters (Section 4.2); `Negative Head` encodes a prior toward â€œNoâ€-like outputs in binary decision tasks (Section 4.2).
- ICI examples (Section 4.3):
  - Overall structure: `Previous Head`, `Positional Head`, `Rare Words Head`, `Duplicate Head` (Section 4.3.1).
  - Long context: `Retrieval Head` and `Global Retrieval Head` locate target tokens in long sequences (â€œneedleâ€‘inâ€‘aâ€‘haystackâ€) (Section 4.3.1).
  - Syntax: `Subword Merge Head` merges split subwords; `Syntactic Head` marks subjects/objects/modifiers; `Name/Letter Mover Heads` copy key items to the `[END]` position; `Negative Name Mover Head` prevents unwanted copying (Section 4.3.2).
  - Semantics: `Context Head`; `Content Gatherer Head` moves answerâ€‘relevant text to `[END]`; `Sentiment Summarizer` writes sentiment near `[SUM]`; `Subject/Relation Heads` encode attributes; `Semantic Induction Head` captures semantic relations (Section 4.3.3).
- LR examples (Section 4.4):
  - Inâ€‘context learning:
    - `Summary Reader` reads `[SUM]` to infer a sentiment label (Section 4.4.1).
    - `Function Vector`: midâ€‘layer head outputs combine into a vector that encodes the task mapping (Section 4.4.1).
    - `Induction Heads`: detect patterns like â€œ... A B ... A â†’ predict Bâ€ by matching â€œprevious tokenâ€ features supplied by `Previous Head` (Section 4.4.1).
    - `Inâ€‘context Head`: compares `[END]` features with label features, weighting labels by similarity (Section 4.4.1).
  - Effectiveness:
    - `Truthfulness`, `Accuracy`, `Consistency` heads correlate with desirable behaviors and can be steered; `Vulnerable Head` overreacts to spurious inputs (Section 4.4.2).
  - Taskâ€‘specific:
    - `Correct Letter Head` maps answer text to the right choice letter in MCQA; `Iteration Head` updates an iterative state; `Successor Head` increments ordinals; `Inhibition Head` suppresses misleading candidates (Section 4.4.3).
- EP examples (Section 4.5; Table 3):
  - `Mixed Head` aggregates outputs from earlier heads (e.g., Subject/Relation/Induction) into a concise representation for unembedding.
  - Signal amplification: `Amplification Head` and `Correct Head` boost logits of the correct choice near `[END]`.
  - Instruction alignment: `Coherence Head` maintains language consistency; `Faithfulness Head` aligns Chainâ€‘ofâ€‘Thought with actual internal computation.

Step 4 â€” Explain collaboration (â€œcircuitsâ€) across heads (Section 4.6; Figure 9)
- IOI example: a multiâ€‘stage circuit integrates KR (Subject/Relation trigger â€œhuman nameâ€), ICI (Duplicate and Name Mover heads spotlight â€œJohn/Maryâ€ at `[END]`), LR (Induction and Previous Heads aggregate evidence; `Inhibition Head` suppresses â€œJohnâ€), and EP (`Amplification Head` boosts â€œMaryâ€)â€”see Figure 9 for the full pathway.
- Additional examples:
  - Parity/iteration (Eq. 5): a `Mover Head` forwards the `[EOI]` index to `[END]`; an `Iteration Head` queries â€œare you position t?â€ and updates the state (Section 4.6).

Step 5 â€” Methods to discover and validate head functions (Section 5; Figure 10)
- Modelingâ€‘Free (no new models) (Table 4):
  - `Modificationâ€‘Based`:
    - Directional addition/subtraction assume linear feature directions (e.g., â€œsentiment directionâ€) and add/remove them at specific heads to measure output effects (Section 5.1).
  - `Replacementâ€‘Based`:
    - Zero/mean ablation replace a headâ€™s activation with zeros or datasetâ€‘means.
    - NaÃ¯ve activation patching swaps activations from a â€œcorruptedâ€ prompt (e.g., swapping the name â€œMaryâ€â†’â€œAliceâ€) at specific heads to test causal roles (Figure 5; Section 5.1).
- Modelingâ€‘Required (new models or metrics) (Table 5):
  - `Trainingâ€‘Required`:
    - Probing: train a classifier on head activations to detect functional heads (Section 5.2).
    - Simplified model training: learn a small attentionâ€‘only or twoâ€‘layer model on synthetic tasks to study head formation (Section 5.2).
  - `Trainingâ€‘Free`:
    - Scoring functions: `RetrievalScore_â„“^h` (Eq. 6) measures how often a head assigns top attention to the true target; `NAS_â„“^h` (Eq. 7) quantifies negative bias by contrasting attention to â€œYes/Noâ€ tokens (Section 5.2).
    - Information Flow Graph (IFG): build a tokenâ€‘level graph of information transfer and prune to the most impactful edges to reveal routes (Section 5.2).

Step 6 â€” Evaluation resources (Section 6)
- Mechanism exploration benchmarks (Table 6) simplify tasks to tokenâ€‘level readouts (e.g., IOI, sentiment templates in Figure 11, induction datasets).
- Common evaluation (Table 7) tests whether manipulating heads improves broader capabilities (e.g., TruthfulQA, MMLU, longâ€‘context retrieval).

## 4. Key Insights and Innovations
- A cognitively grounded, fourâ€‘stage framework for head functions (Section 4; Figure 6)
  - Novelty: Instead of listing heads piecemeal, the survey maps them to KR/ICI/LR/EP and explains where they tend to reside in depth (Figure 8).
  - Significance: Clarifies â€œwho does what, whenâ€ during inference, making interâ€‘head roles and transitions explicit.

- A comprehensive taxonomy of special heads with concrete mechanisms (Figure 7; Sections 4.2â€“4.5; Tables 2â€“3)
  - Novelty: Brings together disparate findingsâ€”e.g., `Induction`, `Mover`, `Retrieval`, `Inhibition`, `Amplification`, `Truthfulness` headsâ€”under one operational vocabulary tied to QK/OV roles.
  - Significance: Offers readyâ€‘made handles for targeted interventions (e.g., suppress `Vulnerable Head`, amplify `Correct Letter Head`), and connects many works to common primitives (read via QK, write via OV).

- A unifying view of head collaboration as circuits (Section 4.6; Figure 9)
  - Novelty: Shows endâ€‘toâ€‘end flows across stages on concrete tasks (IOI, parity), not just singleâ€‘head anecdotes.
  - Significance: Encourages circuitâ€‘level design and evaluationâ€”e.g., combining `Name Mover`, `Induction`, and `Inhibition` heads to steer outputs.

- Methodological reframing of interpretability toolkits (Section 5; Figure 10)
  - Novelty: Reâ€‘organizes techniques by modeling dependency (Modelingâ€‘Free vs Modelingâ€‘Required) and by how activations are altered (Modification vs Replacement).
  - Significance: Helps practitioners pick the right tool for the causal question (e.g., linear feature tests via directional addition; logical elimination via zero ablation; route discovery via IFG).

These are foundational rather than incremental: they consolidate mechanisms into a functional theory of head roles and provide a methodological map to probe and edit them.

## 5. Experimental Analysis
Because this is a survey, it synthesizes experimental designs and results rather than presenting a single new empirical study. Key elements:

- Evaluation methodology (Section 6)
  - Mechanismâ€‘level datasets (Table 6):
    - Sentiment templates `ToyMovieReview` and `ToyMoodStory` (Figure 11) to isolate sentiment features and test `Sentiment Summarizer` and `Summary Reader`.
    - IOI to examine `Name Mover`, `Induction`, and `Inhibition` circuits (Figure 9).
    - Induction/iteration/succession datasets to study `Induction`, `Iteration`, `Successor` heads.
    - Worldâ€‘capital and LREl to probe factual recall (`Memory`/`Mixed` heads).
  - Systemâ€‘level benchmarks (Table 7):
    - Knowledge/logic: MMLU, TruthfulQA, LogiQA, MQuAKE.
    - Sentiment: SST/SSTâ€‘2, ETHOS.
    - Long context: Needleâ€‘inâ€‘aâ€‘Haystack.
    - Text comprehension: AG News, TriviaQA, AGENDA.

- Metrics and causal tests
  - `Logit lens` maps intermediate activations to token logits to quantify intervention effects (Section 3.2.2).
  - Direct/indirect/total effects when patching (Figure 5).
  - Headâ€‘specific scores: `RetrievalScore` (Eq. 6) for longâ€‘context retrieval ability; `NAS` (Eq. 7) for negativeâ€‘bias diagnosis.

- Representative findings the survey grounds in figures/equations
  - â€œNeedleâ€‘inâ€‘aâ€‘Haystackâ€ ability is attributable to `Retrieval Heads`, made measurable by `RetrievalScore_â„“^h` (Section 5.2, Eq. 6).
  - Binary decision bias is quantifiable via `NAS_â„“^h`; high values indicate attention skew toward negative tokens (Section 5.2, Eq. 7).
  - Circuits for IOI integrate KRâ†’ICIâ†’LRâ†’EP, with explicit head roles and dataflow (Figure 9).
  - Layer distribution aligns with KRâ†’EP progression (Figure 8), but deep layers sometimes return to KR/ICI for specific tasks (Section 4.6).

- Do the experiments support the claims?
  - The survey consistently ties mechanisms to causal tools (activation patching, ablations) and to simplified tasks that expose tokenâ€‘level effects (Section 5; Table 6). The use of direct/indirect/total effects (Figure 5) and logitâ€‘lens readouts adds quantitative grounding.
  - However, as a survey, it does not present metaâ€‘analyses or unified effect sizes across models/tasks; evidence is taskâ€‘ and modelâ€‘specific (explicitly noted in Section 8.1 on generalizability).

- Ablations and robustness checks
  - Replacement methods (zero/mean ablation) test necessity of a head (Table 4).
  - Directional addition/subtraction test linearity and feature causal potency (Section 5.1).
  - IFG route pruning tests whether the discovered circuit is sufficient to carry most of the effect (Section 5.2).

- Failure modes and mixed results
  - `Vulnerable Heads` can overâ€‘attend to irrelevant forms, harming accuracy (Section 4.4.2).
  - `Negative Heads` can inject prior bias in binary tasks (Section 4.2), requiring correction (Eq. 7 gives a way to detect it).
  - Heads are not universally stable across models or tasks (Section 8.1).

## 6. Limitations and Trade-offs
- Assumptions
  - Many methods assume meaningful linear directions in activations (e.g., sentiment or truthfulness vectors) that can be added/subtracted (Section 5.1). This may not capture nonâ€‘linear interactions or feature entanglement in all contexts.
  - Circuit descriptions assume modularity of head roles and sparse pathways; real models may use overlapping or distributed mechanisms.

- Scope constraints
  - Focus on decoderâ€‘only LLMs and attention heads (Section 2). FFN mechanisms are summarized but not the main emphasis (Section 7.1).
  - Many head discoveries rely on synthetic or templated tasks to cleanly expose mechanisms (Table 6), which may differ from openâ€‘ended applications.

- Generalizability and transfer
  - Mechanisms validated on one model may not transfer to others; crossâ€‘series reproducibility is underexplored (Section 8.1 â€œLack of Mechanism Transferabilityâ€).
  - Circuits found for IOI or colorâ€‘object tasks are not yet shown to hold broadly across task families (â€œLack of task generalizabilityâ€; Section 8.1).

- Collaboration coverage
  - While notable circuits are mapped (Figure 9), a comprehensive account of multiâ€‘head collaboration across all layers and tasks remains open (Section 8.1).

- Theoretical underpinnings
  - Despite strong empirical tooling, formal guarantees or proofs of necessity/sufficiency for circuits are limited (â€œAbsence of theoretical supportsâ€; Section 8.1).

- Practical tradeâ€‘offs
  - Interventions (e.g., boosting `Amplification` heads) may improve one metric but risk overfitting to specific templates or reduce robustness elsewhere; the survey encourages careful evaluation (Section 6), but standardized tradeâ€‘off reporting is still rare.

## 7. Implications and Future Directions
- How this work changes the landscape
  - It reframes attentionâ€‘head interpretability from isolated observations to a staged theory of reasoning that aligns with model math (QK/OV readâ€‘write; Eq. 4) and cognitive analogies (Figure 6). This helps researchers and practitioners discuss and target interventions at the right stage and depth (Figure 8).

- Enabled followâ€‘ups
  - Circuitâ€‘level editing: Combine `Name Mover` + `Induction` + `Inhibition` + `Amplification` edits to steer IOIâ€‘like phenomena (Figure 9).
  - Bias detection/correction: Use `NAS` (Eq. 7) to find and mitigate `Negative Heads` in safetyâ€‘critical binary decisions.
  - Longâ€‘context optimization: Identify `Retrieval Heads` via `RetrievalScore` (Eq. 6) for KVâ€‘cache compression or latency reduction while preserving retrieval (Section 4.3.1; Section 5.2).
  - Truthfulness and consistency: Probe for `Truthfulness`, `Accuracy`, `Consistency` heads and perform inferenceâ€‘time intervention (Section 4.4.2).

- Research directions highlighted (Section 8.2)
  - Tackle complex tasks (openâ€‘ended QA, math, tool use) to test whether the KRâ†’EP framework scales without heavy templating.
  - Promptâ€‘robust mechanisms: study why small prompt changes flip outcomes and which heads/circuits mediate this sensitivity.
  - New experimental designs: tests for mechanism indivisibility and universality; automated discovery (e.g., scaling IFG, circuit search).
  - Integrate `Machine Psychology` (Section 7.2): design behavioral experiments that map cleanly onto KR/ICI/LR/EP and residualâ€‘stream operations.
  - Build a comprehensive interpretability framework that covers attentionâ€‘FFN coâ€‘operation (Section 7.1) and offers theoretical grounding.

- Practical applications
  - Safety and reliability: steer `Truthfulness`/`Faithfulness` heads during inference to reduce hallucinations and improve Chainâ€‘ofâ€‘Thought fidelity (Section 4.5).
  - Multilingual and instruction following: leverage `Coherence Heads` to keep output language consistent with the prompt (Section 4.5).
  - Retrievalâ€‘augmented systems: identify and preserve `Retrieval` circuits when compressing or pruning models (Section 4.3.1; Section 5.2).
  - MCQA and structured tasks: use `Content Gatherer` + `Correct Letter` + `Amplification` pipelines to improve option mapping and final choice selection (Sections 4.3.3, 4.4.3, 4.5).

> Anchors for further reading in the paper: Figures 3â€“4 (model math and residual streams), Equations 3â€“4 (QK/OV readâ€‘write), Figure 7 (taxonomy of heads), Figures 8â€“9 (layer distribution and collaboration), Table 4â€“5 (method taxonomies), Equations 6â€“7 (scoring functions), and Tables 6â€“7 (evaluation resources).
