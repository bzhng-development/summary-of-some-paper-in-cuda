# ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools

**ArXiv:** [2406.12793](https://arxiv.org/abs/2406.12793)

## ðŸŽ¯ Pitch

ChatGLM introduces a cutting-edge family of bilingual (Chineseâ€“English) large language models, culminating in the GLM-4 series and the agentic GLM-4 All Tools model. These models not only rival GPT-4 and other leading systems on reasoning, coding, and ultra-long context tasks, but also seamlessly integrate autonomous tool useâ€”allowing them to understand user intent, plan multi-step tasks, and dynamically invoke web, code, and generative tools for real-world applications. This advances the frontiers of safe, accessible, and practical LLMs with deep Chinese capabilities, offering open models that democratize high-level AI and empower complex, end-to-end task automation across languages.

---

## 1. Executive Summary
ChatGLM presents an evolving family of large language models culminating in the `GLM-4` series and the `GLM-4 All Tools` agentic model. It tackles two problems at once: building bilingual (Chineseâ€“English) foundation models that rival frontier systems on standard reasoning, coding, and longâ€‘context tasks, and aligning them to autonomously plan and use external tools (browser, Python, image generation, and user APIs) to complete complex tasks.

## 2. Context and Motivation
- Problem or gap
  - Strong generalâ€‘purpose LLMs with robust Chinese ability and longâ€‘context competence have lagged behind bestâ€‘inâ€‘class Englishâ€‘centric models. At the same time, real applications increasingly demand agentic behavior: understanding user intent, planning, and selectively calling tools. Section 1 lays out this dual goal: competitive base capability plus integrated tool use at scale (128Kâ€“1M tokens).
- Importance
  - Real-world: enterprise and consumer tasks often require upâ€‘toâ€‘date information retrieval, numerical computation, or image generation; an LLM that can autonomously decide when and how to invoke these tools provides endâ€‘toâ€‘end task completion (Figure 2 shows a browserâ€‘plusâ€‘Python workflow for computing population CAGR).
  - Theoretical/engineering: pushing stable training to â€œten trillionsâ€ of tokens for bilingual data, extending context windows from 2K to 128K/1M, and aligning longâ€‘context usage (Sections 2 and 3) are nonâ€‘trivial advances in data engineering, architecture, and alignment.
- Prior approaches and shortcomings
  - GPTâ€‘3/3.5/4 popularized instruction tuning and RLHF but focused primarily on English and did not openâ€‘source intermediate, smaller variants. Open models (OPT, BLOOM, LLaMA) provided foundations but lacked strong Chinese alignment, native toolâ€‘use alignment, or longâ€‘context performance up to 128Kâ€“1M with competitive alignment (Section 1; Figure 1 timeline).
- Positioning relative to existing work
  - ChatGLM evolves from `GLM-130B` (2022) with an alternative pretraining objective (autoregressive blank infilling), into `ChatGLM-6B/2/3`, and finally `GLMâ€‘4` and `GLMâ€‘4 All Tools` (Figure 1). It emphasizes:
    - Highâ€‘quality bilingual pretraining and alignment,
    - Longâ€‘context alignment via `LongAlign` (Section 2, â€œChatGLM Techniquesâ€),
    - Agent/toolâ€‘use alignment with function calling and multiâ€‘tool planning (Figure 4; Section 2 â€œGLMâ€‘4 All Toolsâ€),
    - Open releases of capable 9B variants with 128Kâ€“1M context (Table 1, Section 1).

## 3. Technical Approach
This section distills the endâ€‘toâ€‘end system: pretraining data and tokenization; architecture; postâ€‘training alignment; and the â€œAll Toolsâ€ agent pipeline.

- Pretraining data pipeline (Section 2 â€œPreâ€‘Training Dataâ€)
  - Data sources: multilingual web pages, Wikipedia, books, code, research papers; mostly Chinese and English with 24 additional languages.
  - Cleaning and selection:
    - Deduplication: both exact and fuzzy to improve diversity.
    - Filtering: remove noisy or unsafe pages (offensive text, placeholder text, raw code pages when undesired).
    - Tokenization: byteâ€‘level BPE learned separately for Chinese and multilingual corpora, then merged with `cl100k_base` (OpenAIâ€™s tiktoken) to form a 150kâ€‘token vocabularyâ€”this balances Chinese segmentation with compatibility for English and code.
  - Reweighting: higher weights for â€œeducational, highâ€‘quality sourcesâ€ (books, Wikipedia) to improve reasoning/knowledge quality.
  - Scale: roughly â€œten trillionsâ€ of tokensâ€”important for emergent reasoning and longâ€‘context generalization (Section 2).

- Core architecture (Section 2 â€œArchitectureâ€)
  - Base is a Transformer, with design choices aimed at longer contexts and efficient inference:
    - `No Bias Except QKV`: remove most linear biases for speed and better length extrapolation; keep biases only in attentionâ€™s Query/Key/Value projections.
    - `RMSNorm` + `SwiGLU`: swaps LayerNorm/ReLU (or GeLU) for RMSNorm/SwiGLU to improve stability and quality.
    - `RoPE` (rotary position embeddings) extended to 2D to suit GLMâ€™s 2D positional encoding.
    - `GQA` (Group Query Attention): reduces KVâ€‘cache size at inference by sharing keys/values across multiple query heads. Since GQA has fewer parameters than vanilla MHA, FFN width is increased to keep overall model capacity, with `d_ffn = 10/3 Ã— hidden_size`.
  - Longâ€‘context scaling:
    - Position encoding extension methods (ALiBi/RoPE interpolation as in [31, 5]) plus continual training on long text [47].
    - `LongAlign` alignment (see below) to teach the model how to use long context effectively rather than just tolerate it. Context windows progress from 2K (ChatGLM) â†’ 32K (ChatGLM2/3) â†’ 128K and experimental 1M (GLMâ€‘4; Section 2 and Table 1).

- Postâ€‘training alignment (Section 2 â€œAlignmentâ€)
  - `SFT` (supervised fineâ€‘tuning): uses â€œauthentic human prompts and interactions,â€ not synthetic templates, to improve instruction following and conversational helpfulness.
  - `RLHF`: reinforcement learning from human feedback mitigates refusal errors, bilingual mixing in responses, safety behaviors, and multiâ€‘turn coherence.
  - Data sources: first generation (ChatGLMâ€‘6B/130B) used developerâ€‘crafted data; later generations combine inâ€‘house annotations and proprietary thirdâ€‘party data under strict quality control.

- Techniques introduced/used by ChatGLM (Section 2 â€œChatGLM Techniquesâ€; brief definitions)
  - `Emergent Abilities from Loss` [12]: reframes emergence using the pretraining loss threshold at which downstream performance rises above chance; implies that token budget and loss targets govern capability emergence.
  - `LongAlign` [1]: a procedure to align models for long contexts (up to 128K), combining training strategies and evaluation to reach parity with Claude 2 / GPTâ€‘4 Turbo in longâ€‘context chat (Table 5).
  - `ChatGLMâ€‘Math` [48]: a â€œselfâ€‘critiqueâ€ approach to select/curate math reasoning data without external models or heavy manual labeling; targeted at closing math gaps.
  - `ChatGLMâ€‘RLHF` [17]: practical recipes for PPO/DPOâ€‘style preference optimization at scale.
  - `Selfâ€‘Contrast` [24]: â€œfeedbackâ€‘freeâ€ alignment that has the model generate its own negative samples to reduce costly human preference data.
  - `AgentTuning` [52]: instruction tuning with highâ€‘quality agentâ€“environment interaction trajectories to improve tool use and planning.
  - `APAR` [21]: â€œautoâ€‘parallel autoâ€‘regressiveâ€ generation; trains the model to plan hierarchical structures and generate some parts in parallel for responses with inherent structure.

- `GLMâ€‘4 All Tools` agent pipeline (Section 2 â€œGLMâ€‘4 All Toolsâ€; Figure 4)
  - Goal: autonomously break down a userâ€™s complex request, plan steps, and decide which tools (browser, Python, textâ€‘toâ€‘image, user APIs/functions) to call, using intermediate results to guide subsequent actions.
  - Mechanism:
    - Plan/analyze the request,
    - Decide on tool calls; issue structured function calls when needed,
    - Ingest tool feedback/results,
    - Iterate (recursive execute) until task completion,
    - Persist context/memory for multiâ€‘step workflows.
  - Example (Figure 2): searching the web for population data and computing CAGR in Python within the same conversation.

## 4. Key Insights and Innovations
- Longâ€‘context capability that is actually aligned for use (not just supported)
  - Whatâ€™s new: `LongAlign` turns extended context windows (128K/1M) into usable capabilities for summarization, retrieval, and coding with long documents (Section 2; Table 5).
  - Why it matters: many commercial settings involve long reports or legal/technical documents; `GLMâ€‘4 (0520)` matches GPTâ€‘4 Turbo and Claude 3 Opus in English longâ€‘context tasks and exceeds them in Chinese (Table 5).
- Agentic â€œAll Toolsâ€ alignment with autonomous tool selection and planning
  - Whatâ€™s new: a single model aligned to plan and call multiple tools in multiâ€‘round workflows (Figure 4), including userâ€‘defined APIs and knowledge bases. It integrates Python, web browsing, and textâ€‘toâ€‘image into a coherent loop with memory and feedback.
  - Why it matters: shifts LLMs from chatbots to problemâ€‘solving agents; firstâ€‘hand tests show parity or better performance than GPTâ€‘4 All Tools for web access and math via Python (Figure 2; Table 9).
- Bilingual (Chineseâ€“English) alignment at scale with competitive general ability
  - Whatâ€™s new: largeâ€‘scale bilingual pretraining (ten trillion tokens) and alignment â€œprimarily for Chinese and Englishâ€ produces strong general metrics on MMLU/GSM8K/MATH/BBH/GPQA/HumanEval, competitive with frontier models while outperforming on Chinese alignment (Section 3; Tables 2, 4).
  - Why it matters: models serving Chineseâ€‘speaking users often face a tradeoff between Chinese ability and general reasoning; GLMâ€‘4 reduces that gap (Table 4, â€œOverallâ€ 8.00 vs GPTâ€‘4 Turbo 7.90/8.00 and Claude 3 Opus 7.53).
- Practical architecture choices that balance speed, memory, and extrapolation
  - Whatâ€™s new: `No Bias Except QKV`, `RMSNorm + SwiGLU`, 2Dâ€‘RoPE, and `GQA` with scaledâ€‘up FFN width (Section 2).
  - Why it matters: these choices empirically improved length generalization and inference memory (via smaller KV cache) while maintaining model capacity.

## 5. Experimental Analysis
- Evaluation setup (Section 3)
  - Benchmarks span general knowledge (MMLU), math reasoning (GSM8K, MATH), multiâ€‘step reasoning (BBH), graduateâ€‘level science (GPQA), code generation (HumanEval), instruction following (IFEval), Chinese alignment (AlignBench), longâ€‘context chat (LongBenchâ€‘Chat), realâ€‘world coding (NaturalCodeBench/NCB), function calling (Berkeley Function Call Leaderboard), agent tasks (AgentBench), and safety (SafetyBench).
  - Deployment: GLMâ€‘4 and GLMâ€‘4â€‘Air evaluated with bfloat16 precision; longâ€‘context chats are judged by GPTâ€‘4 with fewâ€‘shot prompts and averaged over multiple runs (Table 5).
  - Open model: `GLMâ€‘4â€‘9B` (128K and 1M context) trained with the same postâ€‘training pipeline and released openly (Table 1 and Section 1).

- Headline quantitative results (all numbers taken directly from the cited tables)
  - General academic benchmarks (Table 2)
    - `GLMâ€‘4 (0520)` achieves MMLU 83.3 (vs GPTâ€‘4 86.4; GPTâ€‘4 Turbo 86.7 [2024â€‘04â€‘09]), GSM8K 93.3 (close to GPTâ€‘4 92.0; behind GPTâ€‘4 Turbo 95.6), MATH 61.3 (between GPTâ€‘4 52.9 and GPTâ€‘4 Turbo 73.4), BBH 84.7 (below GPTâ€‘4 Turbo 88.2), GPQA 39.9 (below GPTâ€‘4 Turbo 49.3), HumanEval 78.5 (below GPTâ€‘4 Turbo 88.2).
    - Takeaway: approaches GPTâ€‘4 on average with strengths in GSM8K vs GPTâ€‘4 (not Turbo) but trailing on GPQA/HumanEval vs latest GPTâ€‘4 Turbo.
  - Instruction following (Table 3, IFEval)
    - In English strict instructionâ€‘level accuracy, `GLMâ€‘4 (0520)` 85.0 vs GPTâ€‘4 Turbo (2024â€‘04â€‘09) 85.9 (99% of it); in Chinese strict instructionâ€‘level, 78.0 vs 79.1 (98.6%).
    - Takeaway: nearâ€‘parity with GPTâ€‘4 Turbo on instructionâ€‘following in both English and Chinese.
  - Chinese alignment (Table 4, AlignBenchâ€‘v1.1)
    - `GLMâ€‘4 (0520)` Overall 8.00, higher than GPTâ€‘4 Turbo (1106) 7.90 and Claude 3 Opus 7.53; strongest in Chinese Logic and Language.
    - Caveat: slightly behind GPTâ€‘4 Turbo (2024â€‘04â€‘09) on Math (8.32 vs GLMâ€‘4 7.89).
  - Long context (Table 5, LongBenchâ€‘Chat)
    - English: `GLMâ€‘4 (0520)` 87.3, on par with GPTâ€‘4 Turbo (1106) 87.2 and Claude 3 Opus 87.7.
    - Chinese: `GLMâ€‘4 (0520)` 84.0, above GPTâ€‘4 Turbo (2024â€‘04â€‘09) 82.1 and Claude 3 Opus 82.7.
  - Coding on real user prompts (Table 6, NCB)
    - `GLMâ€‘4 (0520)` Overall 47.1 vs GPTâ€‘4 Turbo (2024â€‘04â€‘09) 53.8 and Claude 3 Opus 48.3.
    - Takeaway: close to Claude 3 Opus; room to close the gap to GPTâ€‘4 Turbo.
  - Function calling (Table 7, Berkeley Leaderboard)
    - `GLMâ€‘4 (0520)` Overall 81.76, comparable to GPTâ€‘4 Turbo (2024â€‘04â€‘09) 81.24; the smaller `GLMâ€‘4â€‘9Bâ€‘Chat` scores 81.00 and notably high Execution Summary 87.92.
    - Insight: function calling quality is not strictly monotonic with model size; alignment and data matter (Table 7 note).
  - Agent tasks (Table 8, AgentBench)
    - Overall score: `GLMâ€‘4 (0520)` 3.79, slightly above GPTâ€‘4 Turbo (1106) 3.77 and Claude 3 Opus 3.62; strongest on Database, Houseâ€‘Holding, Web Shopping; weaker than GPTâ€‘4 on OS/knowledgeâ€‘graph/lateral thinking.
  - Allâ€‘tools performance (Table 9)
    - Pythonâ€‘assisted math: GSM8K 91.59 vs ChatGPTâ€‘4 (Web) 92.72; MATH 63.60 vs 65.00; Math23K 88.50 vs 88.40.
    - Web information seeking: 78.08 vs ChatGPTâ€‘4 (Web) 67.12.
  - Safety (Table 10, SafetyBench)
    - Overall: `GLMâ€‘4 (0520)` 87.2, near Claude 3 Opus 87.5 and behind GPTâ€‘4 (0613) 89.7; largest gap on Physical Health (handsâ€‘on commonâ€‘sense risks).

- Progress across generations (Table 1; Figure 3)
  - `ChatGLMâ€‘6B â†’ ChatGLM2â€‘6B â†’ ChatGLM3â€‘6Bâ€‘Base â†’ GLMâ€‘4â€‘9B` shows monotonic gains: e.g., MMLU 25.2 â†’ 45.2 â†’ 61.4 â†’ 74.7; GSM8K 1.5 â†’ 25.9 â†’ 72.3 â†’ 84.0. This supports that data/architecture/alignment changes accumulate into meaningful capability gains.

- Do experiments support the claims?
  - Claims of â€œclose to GPTâ€‘4/Claude on general benchmarksâ€ are partly supported (Table 2 shows proximity on MMLU/GSM8K but gaps on GPQA/HumanEval vs latest GPTâ€‘4 Turbo).
  - Claims of â€œmatching GPTâ€‘4 Turbo/Claude on longâ€‘contextâ€ are supported by Table 5.
  - Claims of â€œstrong Chinese alignmentâ€ are supported by Table 4.
  - Claims of â€œagentic tool useâ€ have quantitative evidence (Tables 7â€“9) and system schematics (Figure 4). Note: LongBenchâ€‘Chat uses GPTâ€‘4 as judge, which can bias results; the paper mitigates variance by averaging multiple runs (Table 5 notes).

- Missing or limited analyses
  - No detailed ablations isolating the effect sizes of `No Bias Except QKV`, `2Dâ€‘RoPE`, `GQA + wider FFN`, or `LongAlign` components.
  - Limited failure analysis for toolâ€‘use edge cases (e.g., hallucinated tool parameters, unsafe browsing loops).
  - Contamination checks are discussed for HumanEval at a field level but not presented for each benchmark; NCB is used to reduce contamination risk (Section 3.5).

## 6. Limitations and Trade-offs
- Alignment focus and language balance
  - Alignment is â€œpredominantly to Chinese and Englishâ€ (Abstract; Section 3). Performance in other 24 languages is not evaluated here; crossâ€‘lingual generalization remains unclear.
- Benchmarks with LLM-as-judge
  - LongBenchâ€‘Chat scoring uses GPTâ€‘4 as a judge (Section 3.4), which can introduce bias and may favor certain style/formatting. The paper averages multiple runs, but external, humanâ€‘grounded evaluation would further increase confidence.
- Math and specialized science gaps vs latest GPTâ€‘4 Turbo
  - `GPQA` and `MATH` still show gaps compared with the very latest GPTâ€‘4 Turbo numbers (Table 2), though `ChatGLMâ€‘Math` is aimed at closing this.
- Code and realâ€‘world tasks
  - On NCB, `GLMâ€‘4` trails GPTâ€‘4 Turbo (Table 6). Bridging this likely requires additional highâ€‘quality, realâ€‘world programming supervision and toolâ€‘use data.
- Toolâ€‘use robustness and safety
  - While Table 9 shows promising averages, there is limited visibility into failure rates like incorrect API parameterization, browsing loops, or tool invocation cost/latency.
- Compute and scaling
  - Training â€œten trillionsâ€ of tokens implies substantial compute and data curation infrastructure. The paper does not disclose exact compute budgets or carbon/latency tradeâ€‘offs; it introduces `GLMâ€‘4â€‘Air` for lower latency/cost but does not quantify the savings.
- Open model vs closed models
  - The strongest model (`GLMâ€‘4`) is APIâ€‘served; the open model is `GLMâ€‘4â€‘9B`. The capability gap between the open and closed variants remains material (Table 2 vs `GLMâ€‘4â€‘9Bâ€‘Chat` rows; Table 7 execution summary trends).

## 7. Implications and Future Directions
- How this work shifts the landscape
  - Demonstrates that a bilingual model family can approach frontier performance in general reasoning while surpassing them in Chinese alignment and matching them in longâ€‘context tasks at 128K (Table 5). It also normalizes â€œAll Toolsâ€ alignmentâ€”LLMs as planners and tool orchestratorsâ€”not just chatbots (Figure 4; Table 9).
- Followâ€‘up research enabled or suggested
  - Longâ€‘context alignment science: `LongAlign` provides a blueprint; future work can quantify which components deliver the biggest gains, and extend to retrievalâ€‘augmented generation and memory architectures.
  - Math and science reasoning: expand `ChatGLMâ€‘Math` selfâ€‘critique to multimodal math, formal theorem proving, and verifierâ€‘augmented training.
  - Code and realâ€‘world programming: improve NCB performance via curated agent trajectories, executionâ€‘based learning, and stronger functionâ€‘tool ecosystems (e.g., IDE integration).
  - Toolâ€‘use reliability and safety: systematic stress tests for browsing, API calling, and recursive planning; formalize stop conditions, costâ€‘aware planning, and permissioning.
  - Evaluation methodology: reduce reliance on LLMâ€‘asâ€‘judge by adding human evaluation and automated metrics with ground truth where possible.
  - Multilingual expansion: extend alignment beyond Chinese/English to the 24 languages present in pretraining, measuring crossâ€‘lingual parity.
- Practical applications
  - Enterprise assistants for research, data analysis, and operations that require web access, spreadsheetâ€‘like computation (Python), and report summarization over 100Kâ€‘token documents.
  - Developer copilots for data engineering and analytics pipelines with function calling and execution summaries (Table 7).
  - Chineseâ€‘first applications: education, public services, and customer support requiring culturally aligned and safetyâ€‘aware dialogue (Table 4, SafetyBench Table 10).

> In short, Sections 2â€“3 and Tables 2â€“10 show that `GLMâ€‘4` delivers competitive base capabilities, strong Chinese alignment, longâ€‘context proficiency up to 128K (with an experimental 1M variant), and a practically aligned agent that autonomously plans and calls tools. The remaining gapsâ€”math at the frontier level, code on real prompts, and toolâ€‘use robustnessâ€”are visible and tractable targets for the next iterations.
