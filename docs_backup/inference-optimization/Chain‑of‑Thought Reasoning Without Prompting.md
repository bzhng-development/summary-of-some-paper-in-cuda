# Chainâ€‘ofâ€‘Thought Reasoning Without Prompting

**ArXiv:** [2402.10200](https://arxiv.org/abs/2402.10200)
**Authors:** Xuezhi Wang, Denny Zhou
**Institutions:** Google DeepMind

## ğŸ¯ Pitch

CoT-decoding revolutionizes the way large language models execute reasoning by uncovering latent paths through a simple, prompt-free branching mechanism, significantly enhancing accuracy on challenging reasoning benchmarks. This approach not only eliminates the need for costly prompt engineering but also offers a clearer assessment of a model's inherent reasoning capabilities, enabling more efficient and reliable AI deployments in practical applications.

---

## 1. Executive Summary
This paper introduces CoTâ€‘decoding, a decoding-time method that elicits chainâ€‘ofâ€‘thought (stepâ€‘byâ€‘step) reasoning from large language models without any prompting or fineâ€‘tuning. By branching on the first output token, then selecting among the resulting continuations using an answerâ€‘confidence score, the method uncovers latent reasoning paths and substantially improves accuracy on math and commonsense benchmarks across several model families and sizes.

## 2. Context and Motivation
- Problem addressed
  - Most current methods to make language models â€œreasonâ€ depend on crafted prompts (fewâ€‘shot/zeroâ€‘shot chainâ€‘ofâ€‘thought) or instructionâ€‘tuning on large corpora of explanations. This makes it hard to measure a modelâ€™s intrinsic reasoning ability and is costly to deploy.
  - When asked to answer directly in a plain QA format, models often respond with a short guess and perform poorly on reasoning tasks.

- Why this matters
  - Practical: Reduces dependence on laborâ€‘intensive prompt engineering and expensive supervised tuning.
  - Scientific: Separates what the model can already do from what carefully designed prompts â€œteachâ€ it, enabling a fairer assessment of intrinsic capability.

- Prior approaches and their limits
  - Prompting: Fewâ€‘shot CoT (e.g., Wei et al., 2022) and zeroâ€‘shot CoT (Kojima et al., 2022) rely on human examples or specific phrasings; performance varies with prompts and tasks (Â§4).
  - Selfâ€‘consistency: Sample many CoT responses and majorityâ€‘vote (Wang et al., 2023a); still depends on prompts.
  - Instructionâ€‘tuning with CoT data: Effective but costly and still injects human priors into behaviors (Â§1).

- Positioning
  - This paper shows that much of the observed â€œlack of reasoningâ€ under direct QA is an artifact of greedy decoding. Without changing the prompt or training, simply exploring alternative first tokens can reveal existing reasoning paths (Â§2.1, Fig. 1, Table 1).

## 3. Technical Approach
CoTâ€‘decoding is a pure decodingâ€‘time procedure. The input format is the simplest possible QA pattern, `Q: [question]\nA:` (Â§3).

Key terms (defined when first used here):
- `decoding path`: The full sequence of tokens produced when the model generates an answer.
- `greedy decoding`: Always pick the highestâ€‘probability next token.
- `topâ€‘k token`: One of the k most probable next tokens at a decoding step.
- `chainâ€‘ofâ€‘thought (CoT)`: A multiâ€‘step, explicit reasoning trace produced in natural language.

Stepâ€‘byâ€‘step method:
1. Early branching at the very first output token (Â§2.1, Fig. 2).
   - Instead of using the single topâ€‘1 token, enumerate the topâ€‘k alternatives at the first decoding step (default k=10).
   - For each chosen first token, continue the rest of the generation greedily to obtain k distinct decoding paths (plus the k=0 greedy path).

2. Identify the answer span in each path (Â§2.2, â€œIdentify the answer spansâ€).
   - For math: extract the final number or, for PaLMâ€‘2 experiments, append â€œSo the answer isâ€ and align the continuation to identify the answer.
   - For categorical tasks (e.g., â€œeven/oddâ€), parse the final option.
   - For yes/no tasks in symbolic settings, sum probabilities over the valid labels; ignore invalid outputs.

3. Score each path by answer confidence using a marginâ€‘based metric (Â§2.2; blue numbers in Table 1).
   - Intuition: If a path contains a genuine reasoning process, the model will be more decisive when emitting the final answer tokens.
   - Formalization: For each answer token in a path, compute Î” (delta) = probability(top token) âˆ’ probability(second token). Average these margins across all answer tokens to get the pathâ€‘level answer confidence, written as `Î”_k,answer`.
   - This â€œminimumâ€‘marginâ€ style score is robust compared to using raw token probability or entropy (Â§2.2).

4. Select or aggregate paths (Â§2.2, â€œAggregation of the decoding pathsâ€).
   - Maxâ€‘path selection: Output the answer from the path with the highest `Î”_k,answer`.
   - Weighted aggregation: Sum the Î” values for identical answers across paths and choose the answer with the largest total Î” (denoted ËœÎ”_a = Î£_k Î”_k,a). This reduces sensitivity to small logit differences.

Why early branching?
- Fig. 2 shows that branching at the very first token maximizes path diversity. If the first token is a direct guess like â€œ5,â€ later branching rarely recovers a reasoned solution for that path. Some tasks (e.g., â€œyear parityâ€) may benefit from occasional midâ€‘path branching, but the default is to branch only at step 1 for simplicity and cost (Â§2.2).

Why not just sample?
- Without CoT prompts, standard sampling tends to produce directâ€‘answer first tokens with little diversity. CoTâ€‘decoding enforces diversity exactly where it mattersâ€”the first stepâ€”so the model can enter reasoning trajectories (Â§2.2, Table 3).

Complexity and implementation details:
- Complexity is O(k) decoding passes instead of O(1) for greedy (Table 7, rightmost column).
- Default k=10; larger k usually helps, especially on harder tasks (Â§3.1, Fig. 5).
- Illâ€‘formed responses are filtered with simple heuristics (App. D).
  
Toy intuition:
- Imagine a math word problem where â€œA:â€ could start with â€œ5,â€ â€œI,â€ â€œWe,â€ or â€œYou.â€ Greedy might choose â€œ5â€ and immediately answer incorrectly. CoTâ€‘decoding tries â€œI/We/You/Theâ€¦â€ which often lead to a full sentence and a stepâ€‘byâ€‘step explanation that computes the right result (Fig. 1; Table 1).

## 4. Key Insights and Innovations
1. Decoding, not prompting, can elicit latent CoT paths (Â§2.1; Fig. 1; Table 1).
   - Novelty: Prior work focused on prompt engineering or fineâ€‘tuning. This paper shows that many models already contain reasoning trajectories that are simply not selected by greedy decoding.
   - Significance: It reframes poor directâ€‘QA performance as a decoding artifact, not a hard limitation.

2. A simple margin metric over answer tokens correlates with CoT presence and correctness (Â§2.2; Table 1, Table 2).
   - Novelty: Use of average topâ€‘2 probability margins at answer tokens (`Î”_k,answer`) to score confidence, rather than logâ€‘probability of the whole sequence.
   - Significance: On the first 100 GSM8K questions, the topâ€‘Î” path among the topâ€‘10 contained a CoT 88% of the time (Â§2.2). This makes automated CoT path selection practical without any extra models.

3. CoTâ€‘decoding improves reasoning across models, scales, and tasks (Â§3.1; Fig. 3, Fig. 4; Table 4, Table 5).
   - Novelty: A promptâ€‘free procedure that boosts accuracy on math and commonsense tasks for PaLMâ€‘2, Mistralâ€‘7B, and Gemmaâ€‘7B.
   - Significance: Often doubles or triples accuracy over greedy, and narrows the gap to instructionâ€‘tuned models.

4. Insights into intrinsic capabilities vs. â€œtaughtâ€ behaviors (Â§3.2; Table 6).
   - Novelty: By removing prompts, the paper probes which tasks/models already contain correct CoT paths in their decoding space.
   - Significance: Correct paths are common for simpler or more natural tasks (e.g., smallâ€‘step arithmetic, year parity), but rarer for synthetic, multiâ€‘step symbolic tasksâ€”where fewâ€‘shot CoT examples likely play a â€œteachingâ€ role.

5. Complementarity with CoT prompting (Â§3.3; Table 7).
   - Innovation: Combine CoTâ€‘decoding with zeroâ€‘shot CoT prompts and outperform standard selfâ€‘consistency at similar compute via Î”â€‘based aggregation.

## 5. Experimental Analysis
Evaluation setup (Â§3; App. D):
- Input format: `Q: [question]\nA:` for all tasks unless unnatural (e.g., raw arithmetic expression).
- Branch size: k=10 by default; early branching at the first output token; greedy thereafter.
- Models: PaLMâ€‘2 (XS, Small, Medium, Large; also instructionâ€‘tuned), Mistralâ€‘7B (pretrained and instructâ€‘tuned), Gemmaâ€‘7B.
- Datasets/Tasks:
  - Math: GSM8K; MultiArith.
  - Commonsense: â€œYear parityâ€ (query â€œWas [person] born in an even or odd year?â€).
  - Symbolic (BBH and related): Coin Flip; Web of Lies; Multiâ€‘step Arithmetic with varying depth and length.
  - Additional synthetic/natural language: Sports Understanding; Object Counting.

Baselines:
- Greedy decoding, temperature/topâ€‘k/topâ€‘p sampling, beam search (Table 4).
- Selfâ€‘consistency with and without CoT prompts (Table 3, Table 7).
- Alternate path selection heuristics: highest logâ€‘prob, lengthâ€‘normalized logâ€‘prob (Table 2).

Main quantitative findings:
- Path selection metrics (PaLMâ€‘2 L, topâ€‘10 paths) (Â§2.2):
  > Table 2: On GSM8K (first 100 problems), CoTâ€‘decoding reaches 72.0% vs. greedy 44.0%; on Year Parity, 95.0% vs. 57.0%.

- Promptâ€‘free decoding strategies on GSM8K (Mistralâ€‘7B pretrained) (Â§3.1):
  > Table 4: Greedy 9.9%; topâ€‘k sampling 4.9%; topâ€‘p 6.4%; beam 6.7%; temperature 7.5%; selfâ€‘consistency w/o CoT prompt (10 paths) 12.9%; CoTâ€‘decoding 25.1%.

- Promptâ€‘free across models (Fig. 3):
  - Mistralâ€‘7B: GSM8K 9.9% â†’ 25.1%; MultiArith 14.3% â†’ 45.7%; Year Parity 35.0% â†’ 66.0%.
  - PaLMâ€‘2 Large: GSM8K 34.8% â†’ 63.2%; Year Parity ~57% â†’ 95% (see Fig. 4).
  - Gemmaâ€‘7B: Similar relative gains (Fig. 3).

- Scaling behavior (PaLMâ€‘2, Fig. 4):
  > Fig. 4 (left): On GSM8K, CoTâ€‘decoding lifts Large from 34.8% (greedy) to 63.2% and brings the pretrained model closer to the instructionâ€‘tuned model (67.8%).  
  > Fig. 4 (right): On Year Parity, accuracy remains flat across scales under greedy but rises to near 95% with CoTâ€‘decoding at Large.

- Instructionâ€‘tuned models also benefit (Table 5):
  > Mistralâ€‘7B Instruct: GSM8K 31.2% â†’ 38.2%; MultiArith 37.8% â†’ 66.5%; Year Parity 62.2% â†’ 73.5%.

- Effect of branching width k (Fig. 5):
  - Larger k generally yields higher accuracy, with diminishing returns for instructionâ€‘tuned models (they already surface CoT in early paths).

- Synthetic tasks probing intrinsic ability (PaLMâ€‘2 L, Table 6):
  > Coin Flip: 2/3/4 roundsâ€”greedy 70/53/48% â†’ CoTâ€‘decoding 94/57/55%.  
  > Web of Lies: 3/4/5 statementsâ€”76/58/53.6% â†’ 87/63/57.6%.  
  > Multiâ€‘step Arithmetic: accuracy drops sharply as depth/length increase, but CoTâ€‘decoding still helps (e.g., d2,l4: 0% â†’ 16%).  
  > Sports Understanding: small/no gain (58.8% â†’ 58.0%); Object Counting: modest gain (36.0% â†’ 39.2%).

- Combination with CoT prompting (GSM8K test, Table 7):
  > Mistralâ€‘7B: Zeroâ€‘shot CoT 17.5%; selfâ€‘consistency w/ zeroâ€‘shot CoT 39.4%; CoTâ€‘decoding + zeroâ€‘shot CoT (agg) 48.4%.  
  > PaLMâ€‘2 L: Zeroâ€‘shot CoT 75.1%; selfâ€‘consistency w/ zeroâ€‘shot CoT 85.3%; CoTâ€‘decoding + zeroâ€‘shot CoT (agg) 87.0%.

Ablations and diagnostic observations:
- Alternative path selection heuristics underperform marginâ€‘based confidence (Table 2).
- Sampling without prompts does not reliably uncover CoT paths (Table 3).
- Early branching is more effective than later branching in most cases (Fig. 2).
- Qualitative examples show CoTâ€‘decoding surfaces â€œfreeâ€‘formâ€ reasoning different from promptâ€‘taught templates (App. A, Table 8), clarifying what the model can do intrinsically.

Assessment of evidence:
- The study spans multiple models and tasks, reports consistent numeric gains, and includes ablations on k, path scoring metrics, decoding strategies, and combinations with prompts. The evidence supports the central claims that (1) latent CoT paths exist and (2) a marginâ€‘based selector can find them reliably. Results are strongest on math and parity; gains are smaller on certain synthetic language tasks (Table 6), which is candidly discussed.

## 6. Limitations and Trade-offs
- Computational cost (explicitly discussed in Â§5 â€œDiscussion and Limitationsâ€; Table 7):
  - CoTâ€‘decoding requires decoding k paths (O(k) compute), vs. O(1) for greedy. Larger k often helps (Fig. 5) but increases latency and cost.

- Reliance on answer span identification (Â§2.2; App. D):
  - Requires robust parsing of the final answer tokens. Heuristics (last number, final option) or â€œSo the answer is â€¦â€ may fail in openâ€‘ended or poorly formatted outputs.

- Confidence metric can be overconfident on wrong answers:
  - Î” is a local margin at the answer tokens. In adversarial or ambiguous cases, the model may be confidently wrong, and Î” will still be high. Aggregation helps but does not guarantee correctness (Â§2.2, â€œAggregationâ€).

- Task coverage and distributional effects (Â§3.2; Table 6):
  - CoT paths are less prevalent for complex, synthetic reasoning requiring deep state tracking or strict operator precedence; improvements diminish as depth/length grow (e.g., Multiâ€‘step Arithmetic d2,l4: 0% â†’ 16%).

- Branching only at the first token (current default):
  - While empirically effective (Fig. 2), it may miss midâ€‘sequence opportunities in tasks where early tokens are not discriminative. The paper notes branching later is possible but more expensive and nontrivial to score (Â§5 â€œDiscussion and Limitationsâ€).

- Evaluation nuances on factual recall:
  - For yearâ€‘parity with smaller open models (Mistralâ€‘7B), the pipeline first queries the model for the birth year and uses that as reference, omitting names it fails to recall (App. D). This avoids noisy labels but changes the task slightly.

## 7. Implications and Future Directions
- How this changes the landscape
  - Establishes decodingâ€‘time search and selection as a viable, promptâ€‘free route to eliciting reasoning. This helps decouple â€œknowledge already in the modelâ€ from â€œknowledge injected via prompts,â€ enabling cleaner diagnostics of intrinsic capabilities.
  - Suggests that some gaps between pretrained and instructionâ€‘tuned models can be closed by better decoding alone (Fig. 4, Table 5), reducing the need for extensive supervised CoT data in certain settings.

- Practical applications
  - Dropâ€‘in improvement for math/commonsense QA systems that must operate with minimal prompt engineering (e.g., embedded assistants, tutoring tools).
  - A fallback strategy: if greedy decoding yields a terse guess, trigger CoTâ€‘decoding to recover reasoned responses and more reliable final answers.
  - A ranking signal: Î” can serve as a lightâ€‘weight confidence proxy for final answers in structured tasks.

- Research directions
  - Search and efficiency: Explore multiâ€‘step or adaptive branching, perhaps guided by uncertainty or learned policies; combine with speculative decoding to amortize O(k) cost (Â§5).
  - Better confidence signals: Investigate richer tokenâ€‘ or spanâ€‘level uncertainty measures, or internal activationâ€‘space signals, especially for openâ€‘ended answers (Â§5 â€œDiscussion and Limitationsâ€).
  - Process supervision without prompts: Integrate discovered CoT paths to fineâ€‘tune models or to train verifiers/critics that do not depend on handcrafted prompts.
  - Task difficulty curriculum: Use CoTâ€‘decoding to map where latent reasoning exists vs. where explicit â€œteachingâ€ via exemplars is necessary (Table 6), informing targeted data collection.
  - Robust path aggregation: Extend Î”â€‘based aggregation with structureâ€‘aware voting, minor perturbations of the question, or stepâ€‘wise verification (connecting to stepâ€‘checking methods in Â§4).

In short, CoTâ€‘decoding demonstrates that large language models already contain many reasoning trajectories that greedy decoding fails to expose. A simple, promptâ€‘free branching-andâ€‘selection scheme reliably surfaces those paths and improves accuracy across diverse settings, while also clarifying where genuine reasoning is present vs. where models still need guidance.
