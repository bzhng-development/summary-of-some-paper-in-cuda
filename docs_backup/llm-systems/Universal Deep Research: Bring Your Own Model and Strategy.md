# Universal Deep Research: Bring Your Own Model and Strategy

**ArXiv:** [2509.00244](https://arxiv.org/abs/2509.00244)
**Authors:** Peter Belcak, Pavlo Molchanov
**Institutions:** NVIDIA Research

## ğŸ¯ Pitch

Universal Deep Research (UDR) revolutionizes research tools by transforming user-defined strategies into executable code, offering a flexible, model-agnostic system that enhances transparency, efficiency, and control. This advancement enables both individuals and enterprises to tailor workflows for various domains, breaking free from the constraints of hard-coded research systems and ensuring auditability and cost-effectivenessâ€”a significant leap in adapting AI to diverse, specialized needs.

---

## 1. Executive Summary (2-3 sentences)
Universal Deep Research (UDR) is a general-purpose, â€œbring-your-own-modelâ€ agentic system that converts a userâ€™s naturalâ€‘language research strategy into executable code which orchestrates tools, controls a language model, and streams structured progress notifications (Section 2; Figure 2). It addresses the rigidity of existing deep research tools by letting users fully define, edit, and refine research workflows without training or finetuning, enabling transparent, auditable, and costâ€‘efficient research across consumer and enterprise settings (Introduction; Problems P1â€“P3; Conclusions).

## 2. Context and Motivation
- Problem addressed
  - Most deep research tools (DRTs) hardâ€‘code a single research strategy and a fixed model/tool stack, leaving users little control beyond the prompt (Introduction; â€œProblem statement,â€ P1â€“P3).
  - Three concrete gaps are identified:
    - P1: Users cannot enforce source hierarchies, automate crossâ€‘validation against trusted sources, or manage cost/latency tradeâ€‘offs (Problem statement).
    - P2: Specialized strategies needed in highâ€‘value domains (finance, legal, healthcare) are not expressible in current DRTs (Problem statement).
    - P3: Models are not interchangeable; one cannot pair the best model with a preferred deepâ€‘research agent (Problem statement).

- Why this matters
  - Closing P1 raises report quality for individuals and narrows the gap between consumer and enterprise DRTs.
  - Solving P2 enables automation of specialized, laborâ€‘intensive research workflows in highâ€‘value industries.
  - Addressing P3 allows independent competition and pairing between the most competitive models and research agents (Problem importance and impact).

- Prior approaches and shortcomings
  - Consumerâ€‘oriented tools such as Gemini, Perplexity, and OpenAI Deep Research iteratively browse and expand searches via LMâ€‘driven chains of queries (Introduction; â€œGeneral landscapeâ€).
  - Grok 3 DeepSearch adds a twoâ€‘tier crawling infrastructure with chainâ€‘ofâ€‘thought reasoning for credibility checks (Introduction).
  - Enterprise systems often use bespoke, rigid pipelines:
    - NVIDIA AIâ€‘Q Research Assistant: fiveâ€‘step prompt-to-report plan inside curated corpora (Introduction; â€œEnterprise landscapeâ€).
    - SambaNova: documentâ€‘oriented multiâ€‘agent pipeline with sectionâ€‘level planning (Introduction).
    - ERP AI Deep Research: graphâ€‘based data access via knowledge graphs/GNNs (Introduction).
  - Across these, users cannot swap the underlying model freely, nor â€œprogramâ€ the agentic behavior in natural language to enforce policies like source prioritization, validation steps, or budget limits (P1â€“P3).

- How this paper positions itself
  - UDR is a generalist wrapper around any language model that lets the user specify the endâ€‘toâ€‘end research strategy in natural language, which UDR compiles into executable code with a fixed tool API and deterministic control flow (Section 2; Figure 2).
  - It claims a general resolution to P1â€“P3 by making strategy and model interchangeable and userâ€‘defined without additional training (Novelty; Contribution).

## 3. Technical Approach
UDRâ€™s core idea is to transform a humanâ€‘written strategy into a single callable program that runs the entire research workflow deterministically, calls tools synchronously, uses the language model only where explicitly instructed, and streams structured notifications.

Stepâ€‘byâ€‘step:

1) Inputs (Section 2.1)
   - `Research Strategy` (freeâ€‘form natural language): a list or bullet sequence of steps that fully specifies behavior (Appendix A for examples: Minimal, Expansive, Intensive).
   - `Research Prompt`: the userâ€™s topic/task with any content/formatting requirements (Appendix B for examples).
   - Design intent: The strategyâ€”not the modelâ€”controls the flow. There are â€œno implicit restrictionsâ€; any condition must be checked in the strategy logic.

2) Strategy processing â†’ code generation (Section 2.2, â€œPhase 1 â€“ Strategy processingâ€)
   - UDR prompts a language model to â€œcompileâ€ the strategy into source code that:
     - is â€œa single callable function that accepts the research prompt as the input and continuously returns output notificationsâ€ via a generator (yielding dictionaries) (Section 2.2).
     - uses only permitted functions and control structures; tools are documented via a docstring so the generated code knows how to call them.
   - Reliability design choices:
     - The system enforces a oneâ€‘shot endâ€‘toâ€‘end generation of the whole function and requires that each code segment be preceded by a comment quoting the corresponding strategy step. This curbs the tendency to â€œtake shortcuts, skip steps, or impose constraints not stipulated by the user.â€ The paper reports that this approach â€œall but eradicate[s]â€ such behavior across models (Section 2.2, Reliability).
     - Quote for grounding:
       > â€œWe prompted the model to generate code that corresponded to the strategy step by step, explicitly prepending every segment of the generated code by comments laying out the strategy step it corresponds to.â€ (Section 2.2)

   - Why not chain smaller code snippets? Earlier prototypes that decomposed the strategy into isolated fragments or embedded it directly into a reasoningâ€‘oriented LM were â€œfragile and errorâ€‘prone,â€ leading to step skipping and synchronization failures. Endâ€‘toâ€‘end code generation improved coherence (Section 2.2, Reliability).

3) Strategy execution (Section 2.2, â€œPhase 2 â€“ Strategy executionâ€)
   - The generated function executes in an isolated environment (sandbox) and:
     - Maintains state in named variables, not in the LM context window. This lets the system reuse information across steps without inflating prompts.
       - Grounding quote:
         > â€œUDR stores all intermediate information and text fragments as named variables in the code execution stateâ€¦ In our experiments, a context length of 8k tokens was sufficient to carry out full research workflows, regardless of their complexity.â€ (Section 2.2, State modifications)
     - Calls tools synchronously through explicit function calls (e.g., a `search(...)` API), ensuring deterministic behavior (Section 2.2, Tool use).
     - Uses the language model as a local utility (for summarization, ranking, extraction) when the strategy demands it, rather than letting the LM orchestrate the whole process (Section 2.2, LM reasoning):
       > â€œLanguage model reasoning is treated as a callable utility rather than a controlling entity.â€
     - Emits structured progress notifications as `yield`ed dictionaries (with fields like `type`, `timestamp`, `description`). The final report is returned as a last notification with a distinctive type such as `"final_report"` (Sections 2.2 Notifications; 2.3 Outputs).

4) Outputs (Section 2.3)
   - Notifications: a stream of event dictionaries suitable for realâ€‘time UI updates.
   - Final Research Report: structured text/Markdown built from accumulated state (not from an everâ€‘growing LM context), enabling traceability and reproducibility.

5) Security and isolation (Section 2.2, Security)
   - Because UDR executes generated code, it must run in a sandbox that blocks access to the host system and prevents side effects; the paper suggests leveraging engines such as Piston and emphasizes that isolation is a â€œstrict requirementâ€ for nonâ€‘trusted deployments.

6) Efficiency rationale (Section 2.2, Efficiency)
   - Orchestration is CPUâ€‘only code; expensive LM inference happens only where, and on exactly the text, the strategy requests. This â€œdualâ€‘level efficiencyâ€ (code for control; LM for local text tasks) cuts GPU cost and latency.

7) User interface (Section 3; Figures 3â€“4)
   - Includes: search bar, strategy selection, â€œedit strategyâ€ panel, streaming progress notifications, stop button, â€œgenerate reportâ€ for partial results, and a Markdown viewer for the final report.

8) Example strategies (Appendix A)
   - Minimal: generate 3 search phrases â†’ search â†’ aggregate context â†’ one LM call to write report (Appendix A.1; clear stepâ€‘indexed logic).
   - Expansive: first produce 2 topics â†’ per topic, generate up to 2 phrases â†’ search and append to a shared `context` â†’ final synthesis (Appendix A.2).
   - Intensive: iterative refinement over two rounds; uses both a `subcontext` per round and a `supercontext` for all sources; expands phrases after each round based on newly gathered text (Appendix A.3).

9) Example outputs (Appendix B)
   - Demonstrations using `Llama 3.3 70B` with the Minimal strategy, covering varied prompts (culture query, events on a date, market movements, historical figure). They show structured Markdown with sectioning and simple reference lists.

Concepts defined briefly:
- `DRT` (Deep Research Tool): an agent that executes searches and compiles a longâ€‘form, referenced report with progress updates (Introduction; Figure 1).
- `Prompt injection`: malicious content inducing the agent to run unintended actions; UDR mitigates via sandboxing (Section 2.2, Security).
- `Generator`/`yield`: a program function that emits incremental results/event messages over timeâ€”used for progress notifications (Sections 2.2â€“2.3).

## 4. Key Insights and Innovations
1) Strategyâ€‘toâ€‘code compilation with stepâ€‘aligned comments
   - Whatâ€™s new: The system converts a freeâ€‘form strategy into a single, fully executable function whose code segments are explicitly aligned with each written step (Section 2.2, Phase 1).
   - Why it matters: This â€œdisciplined structureâ€ greatly reduces failure modes seen in LMâ€‘orchestrated agents (skipping steps, imposing unstated constraints) and in fragmented code generation. The paper reports that such failures were â€œrarelyâ€ observed after adopting this method (Section 2.2, Reliability).
   - Type: Fundamental innovation in agent specification and enforcement.

2) LM as a local utility, not the global controller
   - Whatâ€™s new: The LM performs bounded tasks (summarize/rank/extract) when explicitly invoked by the code, instead of freeâ€‘running agentic control (Section 2.2, LM reasoning).
   - Why it matters: Improves determinism, traceability, and cost control; reduces susceptibility to prompt drift. This is a notable reframing compared to typical LMâ€‘first agent designs (Figure 1 vs. Figure 2).
   - Type: Conceptual/design innovation with practical cost and reliability benefits.

3) Externalized state enables small context windows and reproducibility
   - Whatâ€™s new: All intermediate text lives in code variables rather than the LMâ€™s context; 8k tokens sufficed in experiments â€œregardless of complexityâ€ (Section 2.2, State modifications).
   - Why it matters: Makes the approach modelâ€‘agnostic and resourceâ€‘efficient; facilitates long workflows without context bloat and supports auditing by inspecting state.
   - Type: Practical systems innovation.

4) Bringâ€‘Yourâ€‘Ownâ€‘Model and Bringâ€‘Yourâ€‘Ownâ€‘Strategy
   - Whatâ€™s new: Users can pair any compatible model with any strategy, edit strategies live, and share a library of strategies (Introduction; Sections 2â€“3; Conclusions R1).
   - Why it matters: Addresses P1â€“P3 headâ€‘onâ€”users can impose source policies and budgets (P1), craft domainâ€‘specific strategies (P2), and swap models at will (P3).
   - Type: Capability innovation that unlocks new enterprise and consumer workflows.

## 5. Experimental Analysis
- Evaluation setup
  - Demonstrations only; no largeâ€‘scale benchmarks. The paper presents example runs using `Llama 3.3 70B` with the Minimal strategy (Appendix B.1â€“B.4).
  - The examples include:
    - A cultural trivia query (â€œunladen swallowâ€) producing a threeâ€‘section report with references (Appendix B.1).
    - â€œSignificant eventsâ€ on a specific date, outputting structured sections and a reference list (Appendix B.2).
    - â€œUS stock movementsâ€ on a specific date with opening/closing summaries and broader context (Appendix B.3).
    - A historical figure (â€œUlysses S. Grantâ€), fiveâ€‘section report with citations (Appendix B.4).
  - The UI supports streaming notifications and early stopping with partial report generation (Section 3; Figure 4).

- Methodological claims vs. evidence
  - Reliability: Section 2.2 claims the endâ€‘toâ€‘end codeâ€‘generation approach â€œrarelyâ€ shows earlier failure modes. This is qualitative; there is no errorâ€‘rate metric or ablation table.
  - Efficiency: Section 2.2 argues for â€œdualâ€‘level efficiencyâ€ and notes that 8k tokens sufficed in their experiments. Again, no runtime/throughput comparison or cost accounting is provided.
  - Security: The system design mandates sandboxed execution (Section 2.2). No penetration tests or redâ€‘team experiments are reported.

- Quantitative results
  - None in tables/figures; all reported evidence is descriptive. The example outputs do illustrate that the generated code follows the specified strategy steps (e.g., notifications like â€œsearch_started,â€ â€œreport_buildingâ€ in Appendix A logic), and the final reports are wellâ€‘structured Markdown.

- Robustness checks and ablations
  - The only â€œablationâ€‘likeâ€ narrative is in Reliability (Section 2.2): earlier prototypes tried (a) embedding the strategy into a reasoning prompt and (b) perâ€‘step code generation; both were â€œfragile.â€ The paper does not include systematic measurements or user studies.

- Overall assessment
  - The demonstrations substantiate feasibility and illustrate UDRâ€™s determinism/transparency, but they do not quantify advantages over existing DRTs. Claims about reliability and efficiency are plausible given the architecture, yet remain to be validated with controlled benchmarks (e.g., stepâ€‘adherence rates, cost/latency vs. LMâ€‘orchestrated agents, success under promptâ€‘injection attempts).

## 6. Limitations and Trade-offs
- Assumptions and dependencies
  - Faithfulness depends on the code generation capability of the chosen language model (Section 4: â€œReliance on language model code generationâ€). Ambiguity in strategies can still induce â€œsemantic drift or hallucinated logicâ€ despite commentâ€‘aligned step enforcement.
  - The system trusts that the userâ€‘authored strategy is coherent and safe; beyond syntax/execution checks, it does not validate overall logic or quality (Section 4: â€œTrust in user-defined strategiesâ€).

- Interactivity constraints
  - Midâ€‘execution user steering is limited: beyond stopping the run or generating a partial report, decisions must be pre-encoded in the strategy (Section 4: â€œLimited real-time interactivityâ€).

- Security and deployment
  - Safe operation requires sandboxing. Any lapse in isolation exposes risks from executing generated code or tool calls (Section 2.2, Security: isolation is a â€œstrict requirementâ€).

- Practicality and user burden
  - Devising robust strategies is â€œtediousâ€ for end usersâ€”even those who want fine control (Conclusions). The paper recommends shipping with a strategy library (R1).

- Scope
  - No coverage of asynchronous tool execution (design allows a â€œfuture upgradeâ€) or distributed crawling; the current emphasis is on determinism and simplicity (Section 2.2, Tool use).

- Evidence limits
  - No quantitative evaluations; no crossâ€‘model comparatives to validate the BYOM advantage; no domainâ€‘specific case studies (e.g., legal/finance) demonstrating P2 at scale.

## 7. Implications and Future Directions
- How this changes the landscape
  - UDR reframes agentic research from â€œLM decides everythingâ€ to â€œcode decides; LM assists.â€ This separation of concerns can standardize agent design around auditable, deterministic control logic while keeping models plugâ€‘andâ€‘play (Figure 2; Sections 2â€“3).
  - For enterprises, it enables codifying compliance policies, source priorities, and validation rules directly in the strategy, making research workflows auditable and reproducibleâ€”key for regulated domains (P1â€“P2).

- Followâ€‘up research enabled
  - Benchmarks for â€œstrategy faithfulnessâ€: measure stepâ€‘adherence, toolâ€‘use correctness, and report traceability across models and strategies.
  - Cost/latency studies comparing UDR to LMâ€‘orchestrated agents under identical tasks and datasets.
  - Automatic strategy synthesis/tuning: converting classes of prompts into deterministic agents (Recommendation R3).
  - Richer user control of model reasoning (â€œthinkingâ€) beyond local utilitiesâ€”investigating safe, bounded CoT under explicit code governance (Recommendation R2).
  - Asynchronous tool orchestration and distributed crawling under the same strategyâ€‘toâ€‘code paradigm.

- Practical applications
  - Enterprise research assistants with enforceable source hierarchies, budget caps, and crossâ€‘validation routines encoded in strategies (P1).
  - Domainâ€‘specialized workflows (e.g., earningsâ€‘call analysis, regulatory document synthesis, legal precedent mapping) by composing tool APIs and step logic without finetuning (P2).
  - Consumer research with â€œstrategy presetsâ€ (Minimal/Expansive/Intensive) and editable templates; marketplaces for vetted strategies (R1).
  - Auditable government/publicâ€‘administration research where deterministic steps and traceable sources are required.

In sum, UDR contributes a method and prototype for turning naturalâ€‘language research procedures into reliable, toolâ€‘calling programs that treat language models as bounded subroutines. The concept is compelling and addresses real gaps (P1â€“P3), but it requires systematic evaluation, richer interactivity, and packaged strategy libraries to reach productionâ€‘grade impact.
