# A Survey of Context Engineering for Large Language Models

**ArXiv:** [2507.13334](https://arxiv.org/abs/2507.13334)

## ğŸ¯ Pitch

This paper introduces Context Engineering as a unified, formal discipline for systematically designing, optimizing, and integrating all facets of contextual information in Large Language Models (LLMs)â€”from retrieval and processing to dynamic assembly and system-level implementation. By synthesizing over 1,400 works, it builds the first comprehensive, end-to-end taxonomy that covers foundational techniques (like prompt engineering, RAG, and memory systems) and their orchestration in real-world AI systems, while highlighting a critical gap: LLMs can deeply comprehend complex contexts but struggle to generate equally sophisticated, long-form outputs. This framework empowers researchers and practitioners to transcend fragmented, ad hoc approaches, laying the groundwork for principled advances in the robustness, scalability, and sophistication of next-generation context-aware AI.

---

## 1. Executive Summary
This survey formalizes Context Engineering for Large Language Models (LLMs) and organizes a fragmented literature (over 1,400 papers) into a unified, endâ€‘toâ€‘end framework. It defines context as a structured, optimizable information payload and presents both foundational components (how to get, process, and manage context) and system implementations (RAG, memory systems, toolâ€‘integrated reasoning, and multiâ€‘agent systems), while identifying a central research gap: LLMs understand complex context far better than they can generate long, highâ€‘quality outputs (Sec. 1; Sec. 5â€“7; Fig. 1).

## 2. Context and Motivation
- Problem addressed
  - LLM performance depends on the â€œcontextâ€ provided at inference, but the fieldâ€™s techniques are siloed: prompt design, external retrieval, long-context handling, memory, tool use, and multiâ€‘agent orchestration are usually studied separately (Sec. 1â€“2).
  - â€œPrompt engineeringâ€ treats context as a single string; this is too narrow for modern systems that need dynamic, structured, and multimodal information (Sec. 3.1; Table 1).
- Why it matters
  - Practical: deployed assistants, RAG systems, code agents, and web agents succeed or fail on how we compose and manage context within strict token, cost, and latency budgets (Sec. 3.2.1; Sec. 5.1â€“5.4; Fig. 2).
  - Theoretical: without a principled definition and optimization target, context design is ad hoc and brittle, leaving performance on the table and obscuring the limits of LLM reasoning (Sec. 3.1; Eq. 3â€“6).
- Prior approaches and shortcomings
  - Prompt engineering (few/zeroâ€‘shot, CoT, ToT) improves reasoning but lacks state, memory, or external knowledge integration, and is sensitive to formatting and length (Sec. 4.1.1; Table 1).
  - Retrievalâ€‘Augmented Generation (RAG) grounds outputs, but pipelines are often linear, poorly optimized endâ€‘toâ€‘end, and hard to adapt to dynamic tasks (Sec. 5.1.1).
  - Longâ€‘context methods extend windows but face quadratic attention costs, positional extrapolation issues, and â€œlostâ€‘inâ€‘theâ€‘middleâ€ failures (Sec. 4.2.1; Sec. 4.3.1).
  - Agents and tool use exist, yet orchestration, memory persistence, and protocol interoperability are immature (Sec. 5.3â€“5.4).
- Positioning
  - The survey reframes context as an optimizable, structured object assembled from multiple sources and maintained over time. It proposes a formal objective, defines a taxonomy (Fig. 1, Fig. 3), maps techniques into the pipeline, and surfaces crossâ€‘cutting insights and evaluation pitfalls (Sec. 3â€“6).

## 3. Technical Approach
This is a survey with a formal framework rather than a single algorithm. Its â€œmethodâ€ is the definition, optimization objective, and taxonomy that connect otherwise separate ideas.

- Formal model: context is structured and optimizable
  - Generation with context: PÎ¸(Y|C)=âˆt PÎ¸(yt|y<t, C) (Eq. 1). Instead of treating `C` as one string, define `C = A(c1,â€¦,cn)`â€”an assembly of components (Eq. 2; Sec. 3.1):
    - `cinstr` (system rules), `cknow` (retrieved knowledge), `ctools` (tool signatures), `cmem` (persistent memory), `cstate` (dynamic system/user state), `cquery` (user request) (Sec. 3.1).
  - Optimization objective: find functions `F={A, Retrieve, Select,â€¦}` that maximize expected task reward under a context length constraint |C| â‰¤ Lmax (Eq. 3; Sec. 3.1).
  - Informationâ€‘theoretic retrieval: choose `Retrieve*` to maximize mutual information between the target answer and retrieved context given the query (Eq. 4; Sec. 3.1).
  - Bayesian context inference: estimate a posterior over contexts P(C|cquery,â€¦) and choose the `C*` that maximizes expected reward (Eq. 5â€“6; Sec. 3.1).
  - Intuition: packing the prompt is like packing a backpack with a strict weight limitâ€”you select, compress, and arrange items to maximize task success (Sec. 3.1; Sec. 4.3.3).
- Context scaling (Sec. 3.1, â€œContext Scalingâ€)
  - Length scaling: technical means to reliably process thousandsâ€“millions of tokens (e.g., sparse/linear attention, stateâ€‘space models, cache management).
  - Structural/multimodal scaling: unify text with tables, graphs, vision, audio, temporal/spatial state, and multiâ€‘agent state.
- Taxonomy: components â†’ implementations (Fig. 1; Fig. 3)
  - Foundational Components (Sec. 4)
    1) Context Retrieval & Generation (Sec. 4.1): prompt and reasoning scaffolds (CoT/ToT/GoT), external retrieval (RAG, KG integration), dynamic assembly (templates, autoâ€‘prompting, tool integration).
    2) Context Processing (Sec. 4.2): longâ€‘context architectures and optimization (SSMs like `Mamba`, `LongNet`; `FlashAttention`; `Ring Attention`; position interpolation like `YaRN`, `LongRoPE`; cache and compression like `StreamingLLM`), selfâ€‘refinement (Selfâ€‘Refine, Reflexion), multimodal integration, and structured/graph reasoning.
    3) Context Management (Sec. 4.3): constraints (e.g., O(nÂ²) attention, â€œlostâ€‘inâ€‘theâ€‘middleâ€), memory hierarchies (`MemGPT`/OSâ€‘like paging), compression (`ICAE`, RCC), and KVâ€‘cache policies (`H2O`).
  - System Implementations (Sec. 5)
    - RAG (Sec. 5.1): modular, agentic, and graphâ€‘enhanced designs (Fig. 4).
    - Memory systems (Sec. 5.2): persistent stores, read/write memory APIs, and evaluation (Fig. 5; Table 6).
    - Toolâ€‘integrated reasoning (Sec. 5.3): function calling, code interpreters, RL for tool use (Fig. 6; Table 7).
    - Multiâ€‘agent systems (Sec. 5.4): protocols (MCP, A2A, ACP, ANP), orchestration patterns, and coordination (Fig. 7).
- Why these design choices?
  - The formal objective (Eq. 3â€“6) gives a principled endâ€‘toâ€‘end lens on context selection, compression, and assembly.
  - The twoâ€‘layer taxonomy mirrors how real systems are built: lowâ€‘level context plumbing (getting, processing, storing information) feeding higherâ€‘level applications (RAG, agents, tools).
  - It exposes crossâ€‘component synergies (e.g., graphâ€‘enhanced RAG + memory + tool calls) and shared bottlenecks (attention scaling, memory persistence, evaluation).

## 4. Key Insights and Innovations
- A unified, formal definition of context as a structured, optimizable object (Sec. 3.1; Eq. 2â€“6; Table 1)
  - Whatâ€™s new: moves beyond â€œprompt as stringâ€ to `C = A(c1,â€¦,cn)` with an explicit optimization target (Eq. 3) and informationâ€‘theoretic/Bayesian retrieval (Eq. 4â€“6).
  - Why it matters: enables principled design choices about what to include, how to compress, and when to retrieve.
- A comprehensive taxonomy that connects components to systems (Fig. 1; Fig. 3; Sec. 4â€“5)
  - Whatâ€™s new: integrates retrieval/generation, processing, and management with RAG, memory, toolâ€‘use, and multiâ€‘agent orchestration.
  - Why it matters: breaks down silos; practitioners can map techniques to pipeline stages and combine them coherently.
- Identification of the â€œcomprehensionâ€“generation asymmetryâ€ (Sec. 1; Sec. 7.2.2)
  - Observation: with advanced context engineering, models can digest complex context, but they still struggle to produce long, logically consistent, factually grounded outputs.
  - Implication: future work needs better longâ€‘form planning, verification, and compact reasoning (Sec. 7.2.2; Table 5).
- Twoâ€‘dimensional â€œcontext scalingâ€ (length and structural/multimodal) (Sec. 3.1)
  - Whatâ€™s new: elevates nonâ€‘textual/structured inputs to firstâ€‘class â€œcontext,â€ not just more tokens.
  - Why it matters: many real tasks need temporal/spatial reasoning, structured sources (tables/graphs), and multimodal fusion (Sec. 4.2.3â€“4.2.4).

## 5. Experimental Analysis
Although a survey, the paper grounds claims with concrete numbers, datasets, and benchmarks across sections.

- Evaluation methodology landscape (Sec. 6; Tables and figures across Sec. 4â€“5)
  - Benchmarks include GAIA for general assistants, GTA for tool agents, WebArena for web agents, BFCL/Tâ€‘Eval/ToolHop for function calling, MEMENTO/LongMemEval for memory, and many longâ€‘context tests (Sec. 6.2; Table 8 shows a WebArena leaderboard).
  - Metrics span task accuracy, success rates, retrieval precision/recall, latency/throughput, and memory recall/adaptation time (Sec. 6.1â€“6.2).
- Representative quantitative results
  - Reasoning scaffolds:
    - Zeroâ€‘shot CoT (â€œLetâ€™s think step by stepâ€) boosts MultiArith from 17.7% to 78.7% (Sec. 4.1.1).
    - Treeâ€‘ofâ€‘Thoughts raises Game of 24 success from 4% to 74% (Sec. 4.1.1).
    - Graphâ€‘ofâ€‘Thoughts improves quality by 62% while cutting cost 31% vs ToT (Sec. 4.1.1).
    - Long chain-of-thought scaling improves reasoning, but at high token cost; pruning/compact prompts can retain accuracy while cutting token usage by up to 87.5% (PREMISE; Table 5; Sec. 4.3.3).
  - Fewâ€‘shot demonstration selection can yield 9.90% BLEUâ€‘4 gains for code summarization and 175.96% EM gains for bug fixing (Sec. 3.2.2).
  - Longâ€‘context efficiency:
    - `StreamingLLM` processes sequences up to 4M tokens with up to 22.2Ã— speedup vs slidingâ€‘window recomputation (Sec. 4.2.1).
    - `H2O` cache policies increase throughput by up to 29Ã— while reducing latency up to 1.9Ã— (Sec. 4.2.1).
    - `LongRoPE` reaches 2,048K context length; `PoSE` extends to 128K; `Selfâ€‘Extend` achieves longâ€‘context without fineâ€‘tuning (Sec. 4.2.1).
  - Toolâ€‘use and web agents:
    - On GTA, GPTâ€‘4 completes <50% of tasks while humans hit 92%â€”a stark capability gap in realistic toolâ€‘use settings (Sec. 5.3.3; Sec. 6.1.2).
    - WebArena leaderboard (Table 8): top success is 61.7% (IBM CUGA), with a long tail of systems between ~23â€“58%. This shows moderate but farâ€‘fromâ€‘solved performance in real web tasks (Sec. 6.2.2).
  - Memory:
    - LongMemEval shows commercial assistants degrade by ~30% accuracy over prolonged interactionsâ€”demonstrating weak memory persistence and retrieval (Sec. 5.2.3).
  - Robustness & evaluation:
    - GAIA: humans 92% vs advanced LLMs ~15% on general assistant tasksâ€”evidence that current systems struggle in openâ€‘ended, toolâ€‘ and reasoningâ€‘heavy scenarios (Sec. 6.3.1).
- Do experiments support claims?
  - Yes, across subsections the numbers repeatedly show that:
    - Context scaffolds dramatically lift reasoning (Sec. 4.1.1).
    - Efficient longâ€‘context processing is possible but still costly and brittle (Sec. 4.2.1).
    - Tool use remains hard in real environments (Sec. 5.3.3; Sec. 6.1.2).
    - Memory systems are immature (Sec. 5.2.3).
  - The survey also documents mixed/conditional outcomes:
    - Longer reasoning often helps but can be pruned without loss in some cases (Table 5).
    - Graph/table linearization vs structural encodings have taskâ€‘dependent tradeâ€‘offs (Sec. 4.2.4).

> â€œCommercial AI assistants exhibit 30% accuracy degradation throughout extended interactionsâ€ (Sec. 5.2.3).

> â€œGPTâ€‘4 completes less than 50% of tasks in the GTA benchmark, compared to human performance of 92%â€ (Sec. 5.3.3; Sec. 6.1.2).

## 6. Limitations and Trade-offs
- Assumptions and constraints
  - Context length is finite, and attention is often O(nÂ²), so the optimization must choose and compress aggressively (Sec. 3.1; Sec. 4.3.1).
  - Many methods assume reliable retrieval and attribution; in practice, context unfaithfulness and hallucination persist (Sec. 3.2.1; Sec. 6.3.1).
- Failure modes and blind spots
  - â€œLostâ€‘inâ€‘theâ€‘middleâ€: models miss information placed midâ€‘context; severe for long contexts and multiâ€‘step reasoning (Sec. 4.3.1).
  - Statelessness: LLMs do not naturally preserve state across sessionsâ€”external memory and orchestration are mandatory (Sec. 4.3.1; Sec. 5.2).
  - Context collapse: larger windows or manyâ€‘shot prompts can blur conversational threads (Sec. 4.3.1).
  - Evaluation brittleness: current benchmarks do not isolate memory vs reasoning vs retrieval; many rely on LLM judges (Sec. 6.1â€“6.3).
- Computational and data costs
  - Longâ€‘context architectures are memory/latency heavy; KVâ€‘cache storage and networked tool calls add overhead (Sec. 4.2.1; Sec. 5.3).
  - Many advanced systems require highâ€‘quality tools, APIs, or KGs that can be expensive to build and maintain (Sec. 5.1.2â€“5.1.3; Sec. 5.3.1â€“5.3.2).
- Security and safety tradeâ€‘offs
  - Tool protocols (e.g., MCP) carry vulnerabilities in discovery/delegation; multiâ€‘agent systems amplify cascaded failures (Sec. 5.4.1; Sec. 6.3.3; Sec. 7.4.2).

## 7. Implications and Future Directions
- How this changes the field
  - The framework reframes â€œpromptingâ€ as a fullâ€‘stack optimization problem over structured, dynamic context. It gives researchers a common language (Eq. 2â€“6) and a map (Fig. 1) for building and evaluating complex systems (Sec. 3â€“6).
- Research enabled/suggested (Sec. 7)
  - Nextâ€‘gen architectures for efficient longâ€‘context: stateâ€‘space models, sliding attention, better positional schemes, and unified memoryâ€‘augmented transformers (Sec. 7.2.1).
  - Advanced reasoning/planning: longâ€‘form planning with verification, compact reasoning traces, and RL for tool orchestration in real environments (Sec. 7.2.2; Table 5).
  - Complex context organization and graph reasoning: unify LLMs with graph formalisms; hybrid neuralâ€‘symbolic approaches; graphâ€‘enhanced RAG and multiâ€‘hop reasoning (Sec. 7.2.3; Sec. 5.1.3; Sec. 4.2.4).
  - Intelligent context assembly: learn `A()` and `Retrieve()` jointly under token and latency budgets, using information theory and Bayesian selection (Sec. 3.1; Sec. 7.2.4).
  - Evaluation: move to â€œlivingâ€ benchmarks, transactional integrity for agents (SagaLLM), and objective, toolâ€‘grounded metrics (MCPâ€‘RADAR, BFCL) (Sec. 6.3; Sec. 7.1.1).
- Practical applications
  - Domain assistants in healthcare, finance, and science with persistent memory, robust tool use, and graphâ€‘grounded retrieval (Sec. 5.1.4; Sec. 4.2.4; Sec. 7.3.1).
  - Enterprise compound AI systems that combine RAG, tools, and agents via standard protocols (MCP, A2A, ACP, ANP) for interoperable ecosystems (Sec. 5.4.1; Sec. 7.3.2; Fig. 2).
  - Longâ€‘horizon embodied or GUI agents with learned memory and planâ€‘thenâ€‘act reasoning under cost/latency constraints (Sec. 5.2; Sec. 5.3; Sec. 7.4.1).

In sum, this survey supplies both the theory (what context is and how to optimize it) and the systems map (how to build with it). It surfaces the pressing challengeâ€”LLMsâ€™ gap between contextual comprehension and sustained, accurate generationâ€”and lays out concrete paths to close it via architectural advances, learned context assembly, robust tool use, and rigorous evaluation (Sec. 1; Sec. 7).
